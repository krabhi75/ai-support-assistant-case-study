# ai-support-assistant-case-study
Designs a guarded AI support assistant that reduces L1 ticket volume using RAG, with clear accuracy, latency, and hallucination controls.
# AI Support Assistant with Guardrails

## Overview
A guarded AI support assistant designed to reduce repetitive L1 SaaS support tickets
while maintaining accuracy, trust, and operational safety.

This project focuses on **AI product decision-making**, not just implementation.

## Problem
Support teams are overloaded with repetitive queries, leading to slower response times,
higher costs, and reduced customer satisfaction.

## Solution Summary
A Retrieval-Augmented Generation (RAG) based AI assistant that answers user questions
using approved documentation, with strong guardrails and fallback to human agents.

## Key AI Decisions
- RAG over fine-tuning to ensure freshness and reduce risk
- Confidence-based fallback to human support
- Source-grounded responses to limit hallucinations

## Success Metrics
- Ticket deflection rate
- Answer accuracy
- CSAT
- Hallucination rate

## Status
ðŸš§ In Progress â€“ v0.1  
Built in public with documented decisions and trade-offs.

## Case Study
ðŸ“„ [AI Support Assistant â€“ Case Study PDF (v0.1)](./artifacts/AI_Support_Assistant_Case_Study_v0.1.pdf)

## Documentation
All product and AI decisions are documented in the `/docs` folder.
